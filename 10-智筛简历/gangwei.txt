岗位职责
大模型开发与优化：

负责大语言模型（如GPT、LLaMA、Claude等）的微调（Fine-tuning）、提示工程（Prompt Engineering）及性能优化（推理加速、量化部署等）；

探索大模型的高效训练方法（如LoRA、P-Tuning、QLoRA等），降低计算资源消耗；

解决模型在实际业务场景中的幻觉（Hallucination）、偏见（Bias）等安全问题。

应用落地与工程化：

基于大模型开发行业解决方案（如智能客服、知识库问答、内容生成等），完成端到端的技术闭环；

结合RAG（检索增强生成）、Agent框架（如LangChain、AutoGen）提升模型在垂直领域的准确性；

设计高并发、低延迟的推理服务架构（如vLLM、TGI），支持企业级需求。

技术研究与创新：

跟踪大模型领域最新进展（如MoE、长上下文优化、多模态理解），推动技术迭代；

参与开源社区贡献，或内部工具链开发（如数据清洗、评估平台）。

任职要求
硬性条件：

学历：计算机、人工智能、数学等相关专业本科及以上学历；

经验：3年以上NLP/大模型相关经验，至少1个完整的大模型落地项目；

技术栈：

精通Python，熟悉PyTorch/TensorFlow框架；

深入理解Transformer架构及大模型关键技术（注意力机制、位置编码等）；

熟悉大模型生态工具（HuggingFace、LangChain、LlamaIndex等）；

有分布式训练（Deepspeed/FSDP）、模型量化（GGUF/AWQ）经验者优先。

加分项：

发表过LLM相关顶会论文（ACL/EMNLP/NeurIPS）；

熟悉大模型安全对齐（Safety Alignment）或垂直领域微调（医疗/法律/金融）；

有云服务（AWS/GCP/Azure）或高性能计算（CUDA、TRT）经验。

软技能：

强烈的技术好奇心，能快速学习并应用新技术；

良好的沟通能力，能协同算法、产品、业务团队推进项目。